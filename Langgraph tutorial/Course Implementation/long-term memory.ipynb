{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5c4b04-5aa3-4077-a7d0-2b699b016fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74c0db8-6f65-4c26-9f55-fc72e75fbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = str(uuid.uuid4())\n",
    "\n",
    "# The value needs to be a dictionary  \n",
    "value = {\"food_preference\" : \"I like pizza\"}\n",
    "\n",
    "# Save the memory\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1969f0f5-8f07-4a1a-8245-0a7b2520af3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories = in_memory_store.search(namespace_for_memory)\n",
    "type(memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa07051-8a1b-4cdf-b665-07af9bdabc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memories'],\n",
       " 'key': 'aff362bc-3b1f-43a2-9397-a60ff7b1ac97',\n",
       " 'value': {'food_preference': 'I like pizza'},\n",
       " 'created_at': '2025-03-19T05:17:51.404361+00:00',\n",
       " 'updated_at': '2025-03-19T05:17:51.404361+00:00',\n",
       " 'score': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metatdata \n",
    "memories[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7e55e2b-fdba-4ee0-a684-c93a8e1c0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aff362bc-3b1f-43a2-9397-a60ff7b1ac97 {'food_preference': 'I like pizza'}\n"
     ]
    }
   ],
   "source": [
    "print(memories[0].key, memories[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b9269e-5721-433a-82bd-51e31c5f47df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memories'],\n",
       " 'key': 'aff362bc-3b1f-43a2-9397-a60ff7b1ac97',\n",
       " 'value': {'food_preference': 'I like pizza'},\n",
       " 'created_at': '2025-03-19T05:17:51.404361+00:00',\n",
       " 'updated_at': '2025-03-19T05:17:51.404361+00:00'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the memory by namespace and key\n",
    "memory = in_memory_store.get(namespace_for_memory, key)\n",
    "memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a425cd6-7488-45c7-9dd2-6e322564d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7276b137-3e5c-404b-9c97-46391adc712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat model \n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8160c1-97e4-40f0-99de-5fc50dd4ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feffa7e-c08b-4e32-a6bb-b765e9c64b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2143bde-e893-48b5-8e9c-ddaeb5cadbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"\"You are collecting information about the user to personalize your responses.\n",
    "\n",
    "CURRENT USER INFORMATION:\n",
    "{memory}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Review the chat history below carefully\n",
    "2. Identify new information about the user, such as:\n",
    "   - Personal details (name, location)\n",
    "   - Preferences (likes, dislikes)\n",
    "   - Interests and hobbies\n",
    "   - Past experiences\n",
    "   - Goals or future plans\n",
    "3. Merge any new information with existing memory\n",
    "4. Format the memory as a clear, bulleted list\n",
    "5. If new information conflicts with existing memory, keep the most recent version\n",
    "\n",
    "Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
    "\n",
    "Based on the chat history below, please update the user information:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cdeaaa5-19f7-42f6-8458-3449dce8b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    key = \"user_memory\"\n",
    "    existing_memory = store.get(namespace, key)\n",
    "\n",
    "    # Extract the actual memory content if it exists and add a prefix\n",
    "    if existing_memory:\n",
    "        # Value is a dictionary with a memory key\n",
    "        existing_memory_content = existing_memory.value.get('memory')\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)\n",
    "    \n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b743c61-1f4b-4a89-aab7-2871dc9c0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "        \n",
    "    # Extract the memory\n",
    "    if existing_memory:\n",
    "        existing_memory_content = existing_memory.value.get('memory')\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
    "\n",
    "    # Overwrite the existing memory in the store \n",
    "    key = \"user_memory\"\n",
    "\n",
    "    # Write value as a dictionary with a memory key\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39d732e1-0af2-4716-b14d-757916c023d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fbaf307-bd75-49c0-8e38-1ba576cfb157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Lance! It's nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc827a2-c0d1-46eb-a85a-b20ad573e0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great way to explore the city! San Francisco has some beautiful routes and views. Do you have any favorite trails or spots you like to visit while biking?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75892b04-dc5f-4fdb-a4dc-a1bffe0814cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Lance! It's nice to meet you. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great way to explore the city! San Francisco has some beautiful routes and views. Do you have any favorite trails or spots you like to visit while biking?\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "state = graph.get_state(thread).values\n",
    "for m in state[\"messages\"]: \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0cdc15f-745a-4945-a3be-e2494a5a2422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'memory': \"**Updated User Information:**\\n- User's name is Lance.\\n- Likes to bike around San Francisco.\"},\n",
       " 'created_at': '2025-03-19T05:27:49.151659+00:00',\n",
       " 'updated_at': '2025-03-19T05:27:49.151659+00:00'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e522a8d0-d22a-4c88-9f45-4d0106bd352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! Where would you recommend that I go biking?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! Biking around San Francisco offers some fantastic routes. Here are a few recommendations:\n",
      "\n",
      "1. **Golden Gate Park**: This is a classic choice with plenty of trails and beautiful scenery. You can enjoy the lush greenery and even stop by the de Young Museum or the California Academy of Sciences.\n",
      "\n",
      "2. **The Embarcadero**: Starting from AT&T Park, you can bike along the waterfront, passing the Ferry Building and continuing towards Fisherman's Wharf. It's a great way to enjoy the bay views.\n",
      "\n",
      "3. **Marin Headlands**: If you're up for a bit of a challenge, you can cross the Golden Gate Bridge and explore the Marin Headlands. The views of the city and the ocean are breathtaking.\n",
      "\n",
      "4. **Presidio**: This area offers a mix of forested trails and coastal views. You can explore the historic sites and enjoy the natural beauty.\n",
      "\n",
      "5. **Twin Peaks**: For a more challenging ride, head up to Twin Peaks. The climb is worth it for the panoramic views of the city.\n",
      "\n",
      "These routes should offer a mix of scenery and challenge to keep your rides interesting. Enjoy your biking adventures!\n"
     ]
    }
   ],
   "source": [
    "# We supply a user ID for across-thread memory as well as a new thread ID\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi! Where would you recommend that I go biking?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b16119e4-c565-4b80-8037-19964c868d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Great, are there any bakeries nearby that I can check out? I like a croissant after biking.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Absolutely, Lance! A croissant sounds like a perfect treat after a ride. Here are a few bakeries in San Francisco where you can find delicious croissants:\n",
      "\n",
      "1. **Tartine Bakery**: Located in the Mission District, Tartine is famous for its pastries, and their croissants are a must-try.\n",
      "\n",
      "2. **Arsicault Bakery**: Situated in the Richmond District, Arsicault has been praised for its buttery, flaky croissants. It's a bit of a ride from the city center, but worth the trip.\n",
      "\n",
      "3. **b. Patisserie**: In Lower Pacific Heights, this bakery offers a variety of pastries, including some fantastic croissants. Their kouign-amann is also highly recommended.\n",
      "\n",
      "4. **Le Marais Bakery**: With locations in the Marina and Castro, Le Marais offers a charming French bakery experience with excellent croissants.\n",
      "\n",
      "5. **Neighbor Bakehouse**: Located in the Dogpatch, this bakery is known for its creative pastries and delicious croissants.\n",
      "\n",
      "These spots should provide you with a delightful post-ride treat. Enjoy your croissant!\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Great, are there any bakeries nearby that I can check out? I like a croissant after biking.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc6ec5-ff02-454f-b250-44373b336ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
