{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2756182d-aecb-41c1-ad02-713a55dd006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe25632-91ad-4b39-acc3-9271cd3a67f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c52a20-921d-4559-8164-5bc394e055ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Memory(content=\"User's name is Lance.\"),\n",
       " Memory(content='User enjoys biking.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(MemoryCollection)\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "memory_collection = model_with_structure.invoke([HumanMessage(\"My name is Lance. I like to bike.\")])\n",
    "memory_collection.memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1965405c-4a64-4051-af66-d11a6278be89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"User's name is Lance.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_collection.memories[0].model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc09431-ebad-4f96-9709-aa365221454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[0].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)\n",
    "\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[1].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1237044f-ddb9-48e1-9f24-0458e3c424da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memories'], 'key': '7dd04cc5-5935-4b2e-9d96-4aba79dc3252', 'value': {'content': \"User's name is Lance.\"}, 'created_at': '2025-03-19T16:20:12.564043+00:00', 'updated_at': '2025-03-19T16:20:12.564043+00:00', 'score': None}\n",
      "{'namespace': ['1', 'memories'], 'key': '64913d30-0652-4640-a861-af6ffd728613', 'value': {'content': 'User enjoys biking.'}, 'created_at': '2025-03-19T16:20:12.564043+00:00', 'updated_at': '2025-03-19T16:20:12.564043+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Search \n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c497a5-0cd0-40d8-87bc-3e921589e1e8",
   "metadata": {},
   "source": [
    "### Updating collection schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "051e22a6-2322-4cb3-a583-c80ed2cae58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q trustcall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba3baf5-4ea5-4aef-ae3e-c637bc4c96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef22286-c50c-439d-8fd2-6afd4ef4f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Lance.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Lance.\"), \n",
    "                HumanMessage(content=\"This morning I had a nice bike ride in San Francisco.\")]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa418c3b-6636-48dc-9e6b-6b9861785a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_DSQPyU5elrNsMXgZnerV5mrx)\n",
      " Call ID: call_DSQPyU5elrNsMXgZnerV5mrx\n",
      "  Args:\n",
      "    content: Lance had a nice bike ride in San Francisco this morning.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b525f754-d897-48d9-b92d-7f72cd5402ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Lance had a nice bike ride in San Francisco this morning.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c1996a3-b4b3-4c0f-9e25-fc36f48de60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_DSQPyU5elrNsMXgZnerV5mrx'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8379791-02cc-4898-862e-930aa8b79df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'Lance had a nice bike ride in San Francisco this morning.'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"), \n",
    "                        HumanMessage(content=\"I went to Tartine and ate a croissant.\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72d4290-eeca-4c19-ba1f-fccd1635e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor.invoke({\"messages\": updated_conversation, \n",
    "                                     \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "335f54f3-d848-45aa-8e60-610f23b81cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_ePJ7RDjTWRdADvfcY2EZ3sYg)\n",
      " Call ID: call_ePJ7RDjTWRdADvfcY2EZ3sYg\n",
      "  Args:\n",
      "    content: Lance had a nice bike ride in San Francisco this morning. After that, he went to Tartine and ate a croissant. He was also thinking about his trip to Japan and going back this winter.\n",
      "  Memory (call_XBPuErvcIJAoGcpW4ypdmxUQ)\n",
      " Call ID: call_XBPuErvcIJAoGcpW4ypdmxUQ\n",
      "  Args:\n",
      "    content: Lance was thinking about his trip to Japan and going back this winter.\n"
     ]
    }
   ],
   "source": [
    "# Messages from the model indicate two tool calls were made\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "778eb013-9bcc-43c0-8cb3-c560b3340446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Lance had a nice bike ride in San Francisco this morning. After that, he went to Tartine and ate a croissant. He was also thinking about his trip to Japan and going back this winter.'\n",
      "content='Lance was thinking about his trip to Japan and going back this winter.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2163103e-24cf-404f-9164-482d19bb86bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_ePJ7RDjTWRdADvfcY2EZ3sYg', 'json_doc_id': '0'}\n",
      "{'id': 'call_XBPuErvcIJAoGcpW4ypdmxUQ'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd5325-3cd3-4eea-9f0d-a959b6073120",
   "metadata": {},
   "source": [
    "## Chatbot with collection schema updating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8736b30-e449-4c45-bc28-c023a95562e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "import uuid\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_core.messages import merge_message_runs\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0a438f2-61f0-4f6a-b275-3a48a7698671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory schema\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "# Create the Trustcall extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    # This allows the extractor to insert new memories\n",
    "    enable_inserts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c8490da-7f01-45e6-9edc-984a916985df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. You are designed to be a companion to a user. \n",
    "\n",
    "You have a long term memory which keeps track of information you learn about the user over time.\n",
    "\n",
    "Current Memory (may include updated memories from this conversation): \n",
    "\n",
    "{memory}\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b5e5fd6-40d2-4919-8641-5fd7e361d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    info = \"\\n\".join(f\"- {mem.value['content']}\" for mem in memories)\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=info)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14e6a5f7-defe-475c-99a7-b42d2a218fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Memory\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = trustcall_extractor.invoke({\"messages\": updated_messages, \n",
    "                                        \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64d92aec-1007-4916-b955-e0c64a256359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bca3cab-cd72-43db-af21-6ebdc40a0424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAFNCAIAAABkBqGXAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXlcVFX/x8+dO/vCMiD7gMimgiyCgmiiuUAKklsampllLvVkWk+LPb8n6/Epf2rmWlqamIoLpVhihZpplmguiJipLKIwLALD7Nude39/jD80GxDxnhnu6b5fvnzN3Hvne78zH86559z7Pd8vRlEUYGEaHFc7wNIVWNkYCSsbI2FlYySsbIyElY2RcF14bqOOaKm3GrSEQWMjCNJGuNCXziIQcnhCjliGi91wnyChq9zAnD9vUzdZyy/qqsr0VjMpEHPEMq7YDZe6cQkrA2aQXD6marAYtDaBmHPrqjE0RtIrRtIzWuJkN5wqm9lo+/Vgs15DyH34oTES/1CR004NA4OWqCrT11WZGm6aUjO9Q2OcJ57zZLt4ovX0dy2pmV4xg92dc0an0VJv+fVgE45jo2f44TjmhDM6SbYfvqz3CRIkPO7phHO5ioZq49drayctCPIJhn7Nc4Zs+9bVxAx2j+wvg32i7sCeVbcyZvi5e/OgngW6bLtW3EzOkPfqJ4V6lm7F3lW3BmV6KSLF8E4Bd952eEdDwnCPv5VmAICnFimKtjcYtBAnNBBb26Vf1BYTmTgC5etZexh1tsM768fNCYRkH1ZrI0nqxNe3/56aAQBEUtw7QHDuqAqSfViy/fptc2qWFyTjjCA1y/vUwWZIxqHIZtARrY2WhOF/06bWxrDJPc4dbYFhGYpsVZf0YjdX3u3sJgSGi66c1sKwDEe2Mr0z7/TYefPNN7/99tuH/VRFRUVmZiYcj4CnDx8AoGq00G6ZftlIktKpiVCn3129cuWK0z7VeXonyW5dNdBulv4JgKrRUri5bvriEHrNtlFQUJCXl1dbWysUCvv37//666/7+vomJSXZ90ql0p9++qmlpWX16tVnzpzRaDS+vr5TpkyZOnWq/YCRI0fOmjWruLj4t99+y8nJ2bZtm337okWLcnJyaPf28il1w03z41N8aLZL0U3NdcPX627RbtbO+fPnExMT9+3bd+vWrUuXLr3wwgszZ86kKKqhoSExMXH37t2tra0URS1YsCA7O/vcuXM3btwoKCgYMGDAsWPH7BbS09MnTpy4Zs2aixcvarXaFStWjBkzRqVSmUwmGA5Xlum+/ayWdrP0Dxz0GkICbTxSUVEhEAiysrK4XG5QUNCyZcvq6uoAAO7u7gAAsVhsf/Haa69xOJzAwEAAQEhISH5+fnFx8bBhwwAAGIYJhcJXXnnFblAgEGAY5uHhAclhiTuuV9toN0v/70tRgCeANR1MSkrCMOyFF17Izs5OTk4OCAjw8nIwOxSJRLm5uWfPnm1tbSVJUqPRKBSKtr2xsbGQ3PsrOI5x+fQ/yqH/9xXLcE2zlXazdnr27Ll169agoKB169aNGzdu5syZZWVl9x1DEMTLL798+vTphQsXbtu2LS8vLyoq6t4DpFLn3SPVq22Mkc2gpb9baCMiImLp0qWHDx/etGkTjuOvvvqqxfKnEXZZWVl5efnixYuTk5N9fX29vb1VKlg3mR4IpEsG/bLJPHkSd5x2s3bKyspKS0sBADiOJyYmzps3r7W1tbn5zj0k+6jYbDa3Xe0AAKWlpUql0lVLHSwm0sufT7tZ+mXjCzk2gqotN9JuGQDw66+/Llq06OjRozU1NVevXt29e7e/v7+fn59AIBAIBOfPn7969WqvXr34fP7u3bubmpqKi4uXL1+ekpJSXV3d0uLgPpNMJmtqarpw4YJ9aEM7f5zVBobRHzIDZewQGi2puqyHYXnWrFnjx49fvXr1pEmTXnrpJYqi1q5di2EYAGDmzJlHjhyZP3++UCh89913T506lZ2dvXnz5iVLluTk5CiVyrlz5/7VYEZGRlBQ0Lx58w4cOEC7t3oNoW8lYMQoQHnepmq0nCpsHvOcP+2WmcXVc9qWevOgsd60W4bS2jx9+FwudvUclLuoDOKXA02xj0GZEcKaF6dmeeevvhWV6Djsx2w2p6enO9xlsVj4fMfX8NDQ0K1bt9Lq5l1yc3Nzc3Md7pJKpTqdzuGuAQMGrFixwuGukuOtEQlSSHceIAYlnPm+ReaJ90l2EBVJUVR7P4TZbObz+fbL1X1wOByJBNYdarPZfN9Eog2r1crjOY7E4nK5IpHjEUfBJ7VjZ/vzeFD6M7iRW1+trhn8pJd/T2ZHH3eBr9bUDB7nBS/sGm7k1qRXgw58qrSaSahn6W58v62ud5IMaqg89DhJG0FtXVI1fn6gV4AA6om6CT98Wd97oCykN9zHjU4KJs9bfjM5Qx4Wi3LApNVMfr2uJm6oR5+BbrDP5bylGz8X3G6oNqdmeQX0QvBSd+pgc811w7DJPj2CnNGpOHWhVF2V8ddvm70D+H49RaExEr6Q8WtZ624Ya8uNxYUtKWPlSSPlTjuvC5YlVl/RXz2nrSrTKyLFEneuxA2XuHFFMpxkwsAFw4CmyarXEAADvxdrPLz54QmSuKEeDmcsEN1wYRag2nJDc51Fr7HpNQQAwGygUze1Wt3Y2BgREUGjTQCA1IOLcYDEjesm5wZFiEVSWM86OsaVskHl1KlTO3fuXL9+vasdgQLjry5/T1jZGAmysuE47u+P7JMjZGWz2WyQHlh3B5CVDcMwsRjiMlzXgqxsFEUZDPQH33cTkJWNw+HAizV2OcjKRpJka2urq72ABbKy4ThuXwOAJMjKZrPZamtrXe0FLJCVDW2QlQ3DMGcu0XAyyMrWQXAYAiArG4ZhMhmyydmQlY2iKK0W2bBoZGVDG2Rlw3Hcx4fu/ATdBmRls9lsjY2NrvYCFsjKhjbIyobjeEBAgKu9gAWystlsNqVS6WovYIGsbGiDrGxsJ8lI2E6SpduBrGxswB0jYQPuWLodyMrGxkkyEjZOkpGwTwAYCfsEgKXbgaxsHA6nLRMoeiArG0mSarXa1V7AAlnZuFwuG0zOPAiCYIPJmQe7dIORsEs3GAmHw5HLnZdNycmglk5m6tSp9ntaJpPJaDR6enoCAIxG4+HDh13tGp2gVtMwLS1ty5YtbW+NRiMA4N4CN2iAWic5ZcqUkJD7S8eNGTPGRe7AAjXZ5HL5iBEj7s03FxgYCKOenmtBTTb75S0oKMj+GsfxrKwsePnMXQWCssnl8rYiAwqF4umnn3a1R/SDoGwAgKeeekqhUOA4Pm7cOPSaGm0jSauZbK6zGHQQy7Y9JIJRg6efPXs2qe/YyjIoRZK6AI5jcj+ezNNxJYiHgoZ52/Gvb5eX6GRynlDsmlSmTEHqwa2+ovfy56eMlfsEPVKZqUeV7butdfIAUd8UZNMk0Y5BR/ywtTbrRX97MfWu8UiyFW1vkAcIopJYzR6aPSuqct5UiGVdvEh1fUhSf8NosZKsZl0jNbvH6e8dVG/sJF2XraXeyuOiORB1Am5yfu31rtcB7frvrtcQ7j5/i7I1MJB58jFO169QXZ8A2AiKIJhQcaFbQlGUusna5aIPbC/HSFjZGAkrGyNhZWMkrGyMhJWNkbCyMRJWNkbCysZIWNkYCSsbI+nusmWPH/Hl9s0AgH3794wYNdD5Dvx0/MjwEUlq9QPqrmSPH7F9x5aOj6GR7i4bi0NY2RiJU9cAWK3W3G2big4X6nTa8PCoObNfiYmJAwCoVC2fblp9/vwZrVbTo4fvhCenTJgwtWunGD9x1LSc527cqPz55DHSZhsz5smpU2asXLX0UukFkVj83My5GelZ9iMLDxXszd+hVNaIROLkganz5i6Uy73s6xk3fPLRkSPfkRQ5KOWxhIQBbcYJgtixc8uPx4oaGup69PCdPGla9rhJNP02D4dTW9unGz8uPFQwf96i1R9/HhioeOOtl5V1tQCA5Svf//1y6f+888Hmz3blPD1zw6erTv7yU9dOweVy9+bvGJyaVrDvyOzZ/9ibv+Ott1/JmTrzQMGP6aMzV69ZptFqAABFRYUrP1o6etTYLzbveX/JimvX/3h78QL7Q8u8XbkHC/fPn79o08ad/folbN+xuc34xk1r9uzdPu3p57Zs3jN50rT1G1YWHiqg7+d5CJwnm16vLzxUMOOZ2cOHjYqK7PPawncGJA2qrb0FAHhp/mvLl2+Ii+uvUISMeSI7PCzy7NniLp8oPDxq0KDHMAx7fHg6AKBv337R0bH2t2azueZWNQAg/6udgwenTct5TqEIiY9P/MfL/7x2/Y+ysosAgKLDhUMGD3siY1xQoCJ73KSkxBS7WZ1Od+Cb/ClPPZOenmnflT46M29XLn2/0EPgvE7yxo0Ki8XSp3e0/S2Px3tvyXL7a5FQlLc7t6TkrFrdSpKkVqsJDOz60iZF0J0VN/bSRApFT/tbsVgCANDpdQRBVFReHz58dNtHoqL6AgDKK6717h1dW3srK3NC264+fWLsTaqi4hpBEG0qAgDi4hILDxUYDAbnJ/dynmxarQYAIBDcH9ZJEMQbb71ss9lefun1YEVPHMf/9e/XHuVEfP6f4g8Fgj8FvFAUZTQZKYqyq2hHLBIDAIxGg9FkBADw+Xc/IhLdkcRg0AMAFr42py2SwN6ptqiaUZbN3cOz7cvfy5UrZZWV5Ws+/jw2NsG+Rd2q8veDmOZYJBRxOJx7PdEb9AAAiUQqFAgBAHr93VJUOt2dQjkSiRQA8M7ipb1Cw++15tPDF56r7eG8a5siKEQoFF4sPW9/S5LkgoWzf/jhoNliBgC4ud3J2HP5cmldvRLq0mQulxseFnmprKRty++XS+1dJZ/P9/P1r6i41rbr3LnT9he9ekXweDyVqiU4uKf9n5ubu7u7x32N2zk4TzapVPpExrideV8UFRVevXZl1ccfXLt2JaZffHhYJJ/P37d/d3Nz029ni9euWz4gKeVWTbVK1fXozwcyefL04uKTe/N31NfXXSg5u27Dyri4/r2j+gIAHn88/eQvPx0s3F9ZWb43f0d5+dU2/zMzJ+Ru2/TjsSJlXe2FkrOvvzF/2fIl8JzsAKfO2+a8uADjcDZ+tsZoNISGhn/43zWBAUEAgDf++e7mzeuLDhdGRvZ5840lt5sa/7P07UWvz926ZS8kT0aOyDCbTXvzd3y+eb1EIh0yeNicOQvsu56d8aJa3bpx02qSJFOSh7z44itL3nuTJEkAwPy5C2VS2Wefr21ubpLLvVIHDX1+1kuQPOyYrkdYFh9qJggsLg3ZJBJQsRFU3oeV81eGde3j7M0tRsKwBBeXLpUs/ter7e3dsf2AuxuyyQjvhWGyRUb2+WxTXnt7ZVJki5HeB8NkEwgEUKd0TIG9tjESVjZGwsrGSFjZGAkrGyNhZWMkrGyMhJWNkbCyMZKuyyYU41w+q3oXoSjKr2fX0251/Xd39+Y13EC2QBpsmpRmiuz6E/yuy6aIEpn03ScTIcO4XWMKi5V2+eNdl43L4wzMkBd9iWyJBHhcPdvadMsYP6zr6coeNTFhbYWxaHtD7FBPT19Bl/O1/U2gKKpZaVY3WxpuGCe8/EiFXGhIA6pVWc8fa228adariUc0RSMkSRIE4ZKwqvbwDhRwOCCkjzh60KM+y0Wt6kYbp06d2rlz5/r1613tCBTYETwjYWVjJMjKxtZvYyRs/TZGwpZLZyRsuXRGwuVy/f39Xe0FLJCVjSCIuro6V3sBC2RlY69tjIS9trF0O5CVDcdxPz8/V3sBC2Rls9ls9fX1rvYCFsjKhjbIyoZhWLd62EYvyMpGUZTFYnG1F7BAVjYMw0Qikau9gAWyslEUZTR2vUBaNwdZ2dAGWdk4HI5cjmzOFGRlI0mypQVi+ifXgqxsaIOsbOwTAEbCPgFg6XYgKxsbcMdI2IA7lm4HsrKxI0lGwo4kGQmGYRKJpBMHMhJkZaMoSq+/v+YAMiArG9ogKxuO42wwOfOw2WxsMDnzwHE8IADZrMrIymaz2ZRKpau9gAWysrHXNkbCXtsYCdrXNtTSycyaNYsgCACAWq1Wq9XBwcH2sqL79u1ztWt0glqWrJCQkG+++aatDuXvv/9u3+hqv2gGtU5y+vTpvr5/qjqJYVhaWprrPIICarKFhYWlpKTc2/MHBwdPmuSaoubwQE02e4Nre9KGYdjQoUPRG5sgKFuvXr3aGlxISMjkyZNd7RH9ICgbAGDmzJn2ufZjjz2GXlPr7EiSsJJGHQnfGdqQuwU+Nmj0mTNnxqZP0qq6UXLSB4JhQOrxYFEeMG+7ckZT+rO6pd4ikuK0usfiGO8AgbLKGJkgS5vojXGw9g7rSLYzRS1NSmt8mlwm50Hzk+V+zEZbs9J0eHvdi8t68QWOr2Ltynb6+xZNM5GSiWzwUzfHaiH3rqya+7+OKzw7FlPVaGmqNbOauRAen5Oa1ePUwSaHex3L1lRrpqh2O1YW5+Dmxa/+w/E6Zsey6dS2HoquV2BhoQVPPyGvnSpCjseaVjNpNUF2iuVBUCTVcNOxDGhOt5GHlY2RsLIxElY2RsLKxkhY2RgJKxsjYWVjJKxsjISVjZGwsjESV8qWPX7El9s3u9AB5uJK2ebPXZiSMsT++skJI+vqkV3XRDuuDCZPT8+0v2hoqFerW13oCePAlyxZ8tettRVGGwH8enY2RfSkpzJMJlNcXH8AQHNz09isodXVlcPSRtr3TpycTlHU9fKri995VREUsmDhbJWqZUBSSvb4EVarlaTI2XNyAABf79tVXnH18eHpBEF8uf3zVas/3LhpzQ9FB3Gc2zuqb8cOVFdXjZ84Kjo69qOPlq7bsOLAN195enqZzKZ/v/v6pxs/PvZTUUREnx7ePvZKU+0ZHz9xFJfLPfTdgf9d8V5e3la1ujU8LHLpB++sWbOs4Jt8mcwtPDzKfmThoYL/fvCvTz5d9dXXeZWV12Oi40QiMQBgyXtvHj9xtKqqfPE7r1IU9erCF5MSk3187hT/KC+/NnFy+sxnX+zkr0qR4NJJ1YDRDnLQ0tNJJiQMKCsrsb++WHrex8f30v+/vXWruqWlOTExmcfjmUzGfft3v/nGkuzsuyGn/WLi//0/HwIANm3c8fab7wMANm5as2fv9mlPP7dl857Jk6at37Cy8FBBxw7gXC4A4Iutn7664K0D+3+M7Zfw8eoPcnM3/uf9j/Z/fcRN5r5u/Qr7kR0Y53K5e/N3DE5NK9h3ZPbsf+zN3/HW26/kTJ15oODH9NGZq9cs02g1AICiosKVHy0dPWrsF5v3vL9kxbXrf7y9eIE9JIfH41VWlV+7/seyD9ZmZU4I8A88fORQm5Mnfj7q7d2Dlh+cHtmS+if/fuUSSZIAgIsXz414PMNg0NcqawAApZcuuLt7hIdFYhhmMpkmTcxJSR4c4H839xyXyxWLJQAAmcxNIpHodLoD3+RPeeqZ9PTMoEBF9rhJ6aMz83bldsaN4cNGBQf3xHF8WNoog8EwZsyT3t49+Hz+0KEjKiqu2VdMdWw8PDxq0KDHMAx7fHg6AKBv337R0bH2t2azueZWNQAg/6udgwenTct5TqEIiY9P/MfL/7x2/Y+ysosAAAoApbLmrTffi4vr7+HhmZEx7tixIqvVajd+/MTR0aPG0vKD09ba9Hp9ZWU5AKDk4rnYfgm9o6IvXbpgb3xJicltK5f69u3XsamKimsEQSQlprRtiYtLVCprDAbDA90IVvS0vxBLJPe+lYglFovFYrE80Lgi6M6SKqlUCgBQtBkUSwAAOr2OIIiKyut9+9z9FlFRfQEA5RXX7lhQhLi73Sli/0TGOL1BX3z6JACgqqri5s0bGelZD/wWnYGeIYmPj69CEXKprMTLy7um5mZMTPyVP8pKSy9kpGeVlp5/dsbd3lwikXZsymDQAwAWvjanTWl7/9OiahaLxR1/lsv7UzwnXyC49y1FUQ80fl99FcFfLBhNRoqi7CraEYvEAACj0fDXL+jt3WPgwNSiosLHhgw/fuJodHSsQkHPSjvaRpL9EwZcvnzR01PeKzRcKpXGxMSvXbe8oaG+oaG+f8LAztuxf+13Fi/tFRp+73afHr7tf8h5xkVCEYfDsctvR2/Qd/DnOPaJJ99f+rZerz/x89EJ46c+mvt3oU22xMTkDZ98JJO5xcb1BwD07dNPqaz56fjh4OCevr6dqqNm/8Pv1SuCx+OpVC3BaXc6qNZWFV11hh7dOJfLDQ+LbBtwAQB+v1za1lX+lZSUIW5u7rt25yqVNcPSRj36V7BD23Q7Pj7p9u3GX0+d6BcTDwCQSCRhvSL2F+xJTEx+4GfdZG4AgOLikzduVEql0szMCbnbNv14rEhZV3uh5Ozrb8xfttzBLKUL0GJ88uTpxcUn9+bvqK+vu1Bydt2GlXFx/dubonC53PTRmbv3fDlkyHD79ZIWaGttMqksMqL3H1d/j+2XYN8S0y9+//49iZ3oISMj+wwcmPrpxo/7xcSv+mjj/LkLZVLZZ5+vbW5uksu9UgcNfX7WS3T5+ejGR47IMJtNe/N3fL55vUQiHTJ42Jw5Czo4fsiQ4Xm7csc8kf3Ivt/F8RqAMz+0WEwgbhiyxUacyabP1hafPrl1y96H/aCNoPI+rJy/0sEyANQyJXQrbt68cfbc6b35O/7z3kp6LTNGtrxdubt2O550BweHbli31ekePZi585+RSKTz5y1KTR1Kr2XGyJaVNXH48NEOd/G43XT53aGDP0OyzBjZZFKZTCpztRfdBfbpNiNhZWMkrGyMhJWNkbCyMRJWNkbCysZIWNkYCSsbI3F8l4QvxEjA5iVxMRgG/Ho6TjPiuLXJPHm3qx0nMmFxGs11ZsLiOLGgY9l8FAKMbWyuRt1kCYl2XIKu3dYWGC488XU9ZMdY2qX1tvnC0ebkdMdPqjtKTHj5lPp6iS4uzcvTl49z2cGLk9C2WJuVplMHbz+/NBTHHXd6D0gDWnVZX3K8tb7KhHMZ1mlSgKJIisNh2F+bT7BQ02wJj5emZnp3cFhnq26YjUxKugsA+O233/bu3btixQpXO/JwYBjgCx/8p9bZx6QCEcP+bHEeSQIz49zuJGh+K+RBVja2XDojYculMxIulxsYGNiJAxkJsrIRBFFbW+tqL2CBrGxsa2MkbGtjJBiGiUSdzfTAOJCVjaIooxHZZ0/IyoY2yMrG5XKRrNxmB1nZCIJQKpFN4oWsbGiDrGwcDsfbu6NHVowGWdlIkmxqclxFCwGQlQ1tkJUNw7AHJntiLsjKRlFUZ7KrMRRkZbOPSlztAiyQ/WL2UYmrXYAFyrIhDLKyYRgmkTiOxEYAZGWjKEqv13fiQEaCrGxog6xsbMAdI2ED7li6HcjKxkZuMRI2coul24GsbBwORyh0nGYAAZCVjSRJk8nkai9ggaxsOI6zQxLmYbPZ2CEJ8+BwOHI5snUMkJWNJMmWlhZXewELZGXjcDgeHh6u9gIWyMpGkmRrK7JlapGVDcdxdg0A87DZbAivAehsFiCmsGjRouPHj1MUxeFwSJK0/+/r6/vdd9+52jU6Qa21Pfvss15eXvZQu7aAu8TERFf7RTOoyRYXF9evX797u5CAgIBp06a51Cn6QU02AMCMGTPuXWsTFxfXp08fl3pEPwjKFhcXFxsba3/t5+c3ffp0V3tEPwjKBgB45pln/P39UW1qTKrf9lDExsZGR0dbLJYZM2a42hcouHgC0HrbUn5RX3fDrG8ljHqbSMZtbTTTYpkkSZIkuVza/i4FIpzHx0RSbo8gQUhvYUgfV4Y8u0y288daS39WE1ZK4iUWewi5fJzLx7kC3CXOdAaSIAmLjTDbCCupbdBpm4yRSe5JI9w9fWmo4/6wuEC2S79ofj3Y5Bkgc/OTCqUu+M60QJGUttlwu1zlHypMm+QlkTn1cuNU2awWsP8TpZXg+EbIufzu27AeClWt1tCsTxju0Xeg87pN58lmNtq2/ac6INpHKkcwFdbNkvqoBFFyhpMezDpJNpPBlr9a6d/XtztfvR4R5e+3Y1MlMYOcUa7YSfO2re/eCOznh7BmAICAvj0uFetLTjjjIZ8zZNu14lZIfz/O36Buh3/vHhdPaGsroWfWg/5Tnv6+hS8Tiz2QjTS9D0W83+GdjbAvPXBlsxHU2cMtXiHIxnT8FQ7OEXuKT3+vgnsWqNZP7G/yi0Q26q09fMLk5w63kDaIDQ6ibKSNLC/RegW7wzvFI7Ji3dP7voVSBMe7l0fJcYgNDqJsVZcNIve/yyXtPmReomvnIS74hyjb9Qt6iReyWa86RuwhVDdZjTobJPsQ76RpVYRHT1iDEZuNOHJ8a8mlw6rWOg9336GpT6cOnAgAaGisWrFu6tznPvn51O6qmxc5GCcuZuS4JxbiOA4AqKwu2X9wZWNjldwz4ImR8yD5ZscrWFpbYQiPgzL7hihbw02jdySs+fXBH9adPlswPuuN0ODYaxVnDhSuwjnc5KRsHOcCAA589/HErDeeC15xveK3Tbkvh4bEx/cbaTTpcnf+098vYsG8XJvNWli0QauFmHDSRgCdClZrg9VJGnU2Hp+DwSlMazTpfj39VdqQ6QMSxnp7KVIHTkxKGPvjz1+2HRAX/XjP4FgAQETYAC/PwJraKwCAK9d+MRg14zNfD/CLUAT2nTrhXYNRA8M9OzgP16mtkIzDks2gJTz8YI1HlHXXbCQRGTawbUtYaP/mlhqz+U4mQn+/iLZdQqHMaNLa+08eT+jn08u+3cPdx90NYuISnohHwFINWicpEOGa22bfKCjG7fJs/GI+uNuaKQCAVtdsf8PjCu49ngKU/VN83p/+kgQCiCMmwkxQ0MzDkk3shpuNsHp2oVACAMiZ/L6/b9i9293dfdXqhvY+xecJTSbdvVuMRi0kDwEAhNkm84R1aYclG4eDCUQ4YbHBeBzq7xeB4zydrsUnZoR9i06vAgDjcTt6Vu7TI8RGEvWNlfZ+sq6hvK11wsBGEBJ3WM/uIY4kvfwFRo1Z5k1/TyESSgcNGP/Dsc8lEg9FYF9Va/2B7z72cPd5fvqqDj7VO3KwgC8uOLhyzOiXbDbrocOfSqWJRTF0AAACYklEQVQQb7yZNRYfBSz7EGWLSBBf/s0AQzYAQFbGApFQVli0XqNtkkm9+kY99sSoB8zDpBKPmTnLCw6t2rD5RU8P/zEj5584tdt+UaQds8EKAOXlL+jEsV0B4tNtvZrIW34rYkgwJPvdmaZqtbe3bdikHpDsQ7y5JXHn+oYIdS3IVuPqAKPaGDPIDZ59uGFig8bKD25ukA5sNz/Iv/47wuF2krRxMA5oZ7b+9sJ9EjFtDxa27FhUVX3R4S6JyF1vVDvctfSdo+0ZbK3Tefng3oGwekhnhAAVbqm3YiIPf6nDvS0qxws+rVYzjvPaywjv4e5HY7J4jaaJsFkc7rJYTHy+45sGcs92VxhfO3kz558KqQfEJgFdNsJKblt6MyxFAfUs3YeWalVwOJ400hPqWaDHknB5nKwX/G78hmxCnntR12kFPAK2Zk6K3PJRCNMmeNVcavf+BRq01uspi3Hs835OOJeTguBCYyRDstxvnEW2zalqNGaV5sm5/s45nVPXANRXm779vM4n3MvdF53CCoTFpq7TuLuTI592XiJ0Z6+4sVrJQ180qBqt3mFeUk9mR5qQNvJ2paq1Tpc2wbv3AIiztL/imvVtDdWmU4dUTUqzRC528xGL3AUcnDExy1YToWk06JsNXB4VGS9JGgV9APJXXLmaVN1srSjVX7+gUzdZSBvgC3GZt9Ckg/Zs8dGgKGDSWy0Gm29PkdyXHxEvCe7tsgCn7pIFyGy06TU2k95GddfiXVwBRyLDJW44xoESafFQdBfZWB4KxlxRWO6FlY2RsLIxElY2RsLKxkhY2RjJ/wGE6DqW9uoocAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcf190c4-c43c-4566-85b1-2330649db9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! It's great to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "782a2798-6a75-49b2-be43-4f2d8ba922c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a lot of fun! San Francisco has some beautiful routes for biking. Do you have a favorite trail or area you like to explore?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49f75e38-aa6d-4111-9bcd-575640e8d4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memories', '1'], 'key': '6ba426b7-ba17-4cbb-8785-1450c0da39d9', 'value': {'content': 'User likes to bike around San Francisco.'}, 'created_at': '2025-03-19T16:29:45.679757+00:00', 'updated_at': '2025-03-19T16:29:45.679757+00:00', 'score': None}\n",
      "{'namespace': ['memories', '1'], 'key': '20f534d2-5ed8-4fff-8251-387a1ac8821e', 'value': {'content': 'User likes to bike around San Francisco.'}, 'created_at': '2025-03-19T16:29:45.679757+00:00', 'updated_at': '2025-03-19T16:29:45.679757+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3d861dd-8410-4561-af5a-37c2bfc49ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Biking and bakeries make a great combination! Do you have a favorite bakery in San Francisco, or are you on the lookout for new ones to try?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "020e8707-83bf-4e35-96bf-65fc475ff120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "San Francisco has some fantastic bakeries! Here are a few you might enjoy:\n",
      "\n",
      "1. **Tartine Bakery** - Known for its delicious bread and pastries, it's a must-visit.\n",
      "2. **B. Patisserie** - Offers a delightful selection of French pastries, including their famous kouign-amann.\n",
      "3. **Arizmendi Bakery** - A worker-owned cooperative with great sourdough and pizza.\n",
      "4. **Craftsman and Wolves** - Known for their inventive pastries and the \"Rebel Within,\" a savory muffin with a soft-cooked egg inside.\n",
      "5. **Mr. Holmes Bakehouse** - Famous for their cruffins and other creative pastries.\n",
      "\n",
      "Since you like biking, you could plan a route that takes you to a couple of these spots!\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b4d68-33c3-4f79-ae9d-f6ae13965df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
